{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "- We'll be using the [spacy](https://www.shanelynn.ie/word-embeddings-in-python-with-spacy-and-gensim/) library for embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell once, it downloads the relevant spacy embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The (300,) [ 2.7204e-01 -6.2030e-02 -1.8840e-01  2.3225e-02 -1.8158e-02  6.7192e-03\n",
      " -1.3877e-01  1.7708e-01  1.7709e-01  2.5882e+00 -3.5179e-01 -1.7312e-01\n",
      "  4.3285e-01 -1.0708e-01  1.5006e-01 -1.9982e-01 -1.9093e-01  1.1871e+00\n",
      " -1.6207e-01 -2.3538e-01  3.6640e-03 -1.9156e-01 -8.5662e-02  3.9199e-02\n",
      " -6.6449e-02 -4.2090e-02 -1.9122e-01  1.1679e-02 -3.7138e-01  2.1886e-01\n",
      "  1.1423e-03  4.3190e-01 -1.4205e-01  3.8059e-01  3.0654e-01  2.0167e-02\n",
      " -1.8316e-01 -6.5186e-03 -8.0549e-03 -1.2063e-01  2.7507e-02  2.9839e-01\n",
      " -2.2896e-01 -2.2882e-01  1.4671e-01 -7.6301e-02 -1.2680e-01 -6.6651e-03\n",
      " -5.2795e-02  1.4258e-01  1.5610e-01  5.5510e-02 -1.6149e-01  9.6290e-02\n",
      " -7.6533e-02 -4.9971e-02 -1.0195e-02 -4.7641e-02 -1.6679e-01 -2.3940e-01\n",
      "  5.0141e-03 -4.9175e-02  1.3338e-02  4.1923e-01 -1.0104e-01  1.5111e-02\n",
      " -7.7706e-02 -1.3471e-01  1.1900e-01  1.0802e-01  2.1061e-01 -5.1904e-02\n",
      "  1.8527e-01  1.7856e-01  4.1293e-02 -1.4385e-02 -8.2567e-02 -3.5483e-02\n",
      " -7.6173e-02 -4.5367e-02  8.9281e-02  3.3672e-01 -2.2099e-01 -6.7275e-03\n",
      "  2.3983e-01 -2.3147e-01 -8.8592e-01  9.1297e-02 -1.2123e-02  1.3233e-02\n",
      " -2.5799e-01 -2.9720e-02  1.6754e-02  1.3690e-02  3.2377e-01  3.9546e-02\n",
      "  4.2114e-02 -8.8243e-02  3.0318e-01  8.7747e-02  1.6346e-01 -4.0485e-01\n",
      " -4.3845e-02 -4.0697e-02  2.0936e-01 -7.7795e-01  2.9970e-01  2.3340e-01\n",
      "  1.4891e-01 -3.9037e-01 -5.3086e-02  6.2922e-02  6.5663e-02 -1.3906e-01\n",
      "  9.4193e-02  1.0344e-01 -2.7970e-01  2.8905e-01 -3.2161e-01  2.0687e-02\n",
      "  6.3254e-02 -2.3257e-01 -4.3520e-01 -1.7049e-02 -3.2744e-01 -4.7064e-02\n",
      " -7.5149e-02 -1.8788e-01 -1.5017e-02  2.9342e-02 -3.5270e-01 -4.4278e-02\n",
      " -1.3507e-01 -1.1644e-01 -1.0430e-01  1.3920e-01  3.9199e-03  3.7603e-01\n",
      "  6.7217e-02 -3.7992e-01 -1.1241e+00 -5.7357e-02 -1.6826e-01  3.9410e-02\n",
      "  2.6040e-01 -2.3866e-02  1.7963e-01  1.3553e-01  2.1390e-01  5.2633e-02\n",
      " -2.5033e-01 -1.1307e-01  2.2234e-01  6.6597e-02 -1.1161e-01  6.2438e-02\n",
      " -2.7972e-01  1.9878e-01 -3.6262e-01 -1.0006e-05 -1.7262e-01  2.9166e-01\n",
      " -1.5723e-01  5.4295e-02  6.1010e-02 -3.9165e-01  2.7660e-01  5.7816e-02\n",
      "  3.9709e-01  2.5229e-02  2.4672e-01 -8.9050e-02  1.5683e-01 -2.0960e-01\n",
      " -2.2196e-01  5.2394e-02 -1.1360e-02  5.0417e-02 -1.4023e-01 -4.2825e-02\n",
      " -3.1931e-02 -2.1336e-01 -2.0402e-01 -2.3272e-01  7.4490e-02  8.8202e-02\n",
      " -1.1063e-01 -3.3526e-01 -1.4028e-02 -2.9429e-01 -8.6911e-02 -1.3210e-01\n",
      " -4.3616e-01  2.0513e-01  7.9362e-03  4.8505e-01  6.4237e-02  1.4261e-01\n",
      " -4.3711e-01  1.2783e-01 -1.3111e-01  2.4673e-01 -2.7496e-01  1.5896e-01\n",
      "  4.3314e-01  9.0286e-02  2.4662e-01  6.6463e-02 -2.0099e-01  1.1010e-01\n",
      "  3.6440e-02  1.7359e-01 -1.5689e-01 -8.6328e-02 -1.7316e-01  3.6975e-01\n",
      " -4.0317e-01 -6.4814e-02 -3.4166e-02 -1.3773e-02  6.2854e-02 -1.7183e-01\n",
      " -1.2366e-01 -3.4663e-02 -2.2793e-01 -2.3172e-01  2.3900e-01  2.7473e-01\n",
      "  1.5332e-01  1.0661e-01 -6.0982e-02 -2.4805e-02 -1.3478e-01  1.7932e-01\n",
      " -3.7374e-01 -2.8930e-02 -1.1142e-01 -8.3890e-02 -5.5932e-02  6.8039e-02\n",
      " -1.0783e-01  1.4650e-01  9.4617e-02 -8.4554e-02  6.7429e-02 -3.2910e-01\n",
      "  3.4082e-02 -1.6747e-01 -2.5997e-01 -2.2917e-01  2.0159e-02 -2.7580e-02\n",
      "  1.6136e-01 -1.8538e-01  3.7665e-02  5.7603e-01  2.0684e-01  2.7941e-01\n",
      "  1.6477e-01 -1.8769e-02  1.2062e-01  6.9648e-02  5.9022e-02 -2.3154e-01\n",
      "  2.4095e-01 -3.4710e-01  4.8540e-02 -5.6502e-02  4.1566e-01 -4.3194e-01\n",
      "  4.8230e-01 -5.1759e-02 -2.7285e-01 -2.5893e-01  1.6555e-01 -1.8310e-01\n",
      " -6.7340e-02  4.2457e-01  1.0346e-02  1.4237e-01  2.5939e-01  1.7123e-01\n",
      " -1.3821e-01 -6.6846e-02  1.5981e-02 -3.0193e-01  4.3579e-02 -4.3102e-02\n",
      "  3.5025e-01 -1.9681e-01 -4.2810e-01  1.6899e-01  2.2511e-01 -2.8557e-01\n",
      " -1.0280e-01 -1.8168e-02  1.1407e-01  1.3015e-01 -1.8317e-01  1.3230e-01]\n",
      "grass (300,) [ 2.1013e-01  4.3992e-01  1.2982e-01 -7.7563e-01  9.2757e-03  1.6448e-01\n",
      " -1.0840e-01  5.8904e-01 -7.3319e-01  1.7751e+00 -2.4964e-01  5.3594e-01\n",
      " -8.4508e-01  2.2709e-01 -2.4014e-01  4.6404e-01  3.0001e-01  1.2308e+00\n",
      "  1.1330e-01  1.3753e-01 -1.5414e-01  6.6534e-01 -4.0810e-01 -4.6946e-02\n",
      "  3.2157e-02  1.3378e-01 -1.6888e-01  4.1766e-01  4.1502e-01 -5.1556e-01\n",
      " -3.5700e-01  1.8851e-01 -1.2286e-01 -6.1559e-01  2.5344e-01  1.6851e-01\n",
      "  2.8670e-01 -6.6317e-02 -2.6548e-01 -4.3537e-01  4.5042e-01  4.4068e-01\n",
      "  2.0772e-02 -5.9397e-02  1.3015e-01  2.4388e-01 -4.3730e-01 -3.1017e-01\n",
      " -1.2205e-01  3.9096e-01 -5.6332e-01  4.1712e-02 -2.5592e-01  6.0034e-01\n",
      "  3.0416e-01  8.5707e-02 -1.3389e-01 -1.3451e-01 -3.0947e-01  1.8826e-01\n",
      " -4.3794e-01  6.0784e-01 -1.0573e-01  2.2650e-01  2.1085e-01 -4.4108e-01\n",
      " -1.9471e-01 -6.1800e-01  6.1198e-02 -4.6044e-01 -8.2030e-01  9.5197e-01\n",
      "  1.6520e-01  5.7251e-01 -5.1675e-02  1.2379e-02  1.0364e-01  3.9404e-02\n",
      "  4.0532e-01 -1.0027e+00  1.6315e-01  8.2909e-01  2.8263e-01  1.5715e-01\n",
      " -2.1538e-01  1.1573e-01  9.3920e-01  1.4918e+00  5.5431e-02  1.2292e-01\n",
      " -3.3674e-01  3.2732e-01 -1.4499e-01 -3.2388e-02 -3.7485e-01  5.6794e-01\n",
      " -5.1672e-02  3.4045e-01 -3.6781e-01 -9.0323e-02 -9.9238e-02  2.5849e-01\n",
      " -4.5047e-01 -4.6218e-01 -4.1886e-01 -1.0347e+00  2.5101e-01  1.4372e-01\n",
      " -2.3330e-01 -2.3294e-01  3.0243e-01 -5.0978e-01  3.4775e-01 -2.6799e-01\n",
      "  1.2167e-02  1.9761e-01  4.7529e-01 -3.6869e-01 -3.5003e-01 -1.2013e+00\n",
      "  1.8582e-03  1.5085e-01 -1.5136e-01 -5.1851e-01 -4.8127e-01 -3.9455e-01\n",
      "  6.8100e-01 -2.7955e-02  2.6054e-01  3.4307e-02 -4.0204e-01 -3.3504e-01\n",
      " -2.7061e-01  2.3238e-01 -1.4549e-01 -4.8311e-01  5.9835e-01  1.6962e-01\n",
      "  5.5283e-01  3.2844e-01 -1.9202e+00  3.8098e-01  2.8631e-01  2.0005e-01\n",
      " -1.9348e-01 -1.2921e-01 -2.3223e-01 -5.3051e-01 -4.6834e-02  4.0692e-01\n",
      " -4.2572e-01 -1.4386e-01  3.1971e-01  3.1602e-01 -4.1314e-01  4.1587e-01\n",
      "  2.1086e-02  2.9738e-01 -2.8799e-02  2.1676e-01 -8.8651e-02 -5.8086e-01\n",
      " -2.1698e-01  4.2501e-01 -8.3987e-02  4.4094e-02 -1.7102e-02 -5.2943e-01\n",
      " -1.9066e-02  3.3707e-01 -1.8848e-01  1.8965e-01 -3.1553e-01 -2.3798e-01\n",
      " -2.9575e-01  1.7400e-01  1.9160e-01  1.4679e-01  3.1017e-01  1.2741e-01\n",
      "  4.3468e-01 -1.8740e-01 -3.9401e-01 -3.6074e-02 -2.0155e-02 -2.6287e-02\n",
      " -2.7206e-01  8.5177e-02  1.1090e-01 -2.5137e-01  1.4108e-01  4.7672e-01\n",
      " -1.0209e-01 -6.4576e-01 -2.0634e-02  8.3778e-01  3.1119e-01  1.5010e-01\n",
      " -4.6969e-01  8.5789e-02 -4.9839e-02 -1.5228e-01 -4.7808e-01  1.8930e-02\n",
      " -2.3747e-01  5.8842e-01  7.6649e-01 -3.9757e-01  6.3165e-01 -1.4225e-01\n",
      " -9.6899e-03  3.9117e-01  9.6516e-01 -6.3456e-02 -4.8682e-02  1.2917e-02\n",
      "  1.9349e-01 -6.6572e-02 -1.4910e-01 -7.6995e-01  1.0978e-01 -6.3797e-01\n",
      "  3.5626e-01 -1.2664e-02  3.1354e-01  4.2215e-01  3.0247e-01 -2.7385e-01\n",
      " -2.9247e-01  5.2662e-01  7.6386e-01  3.5881e-01 -6.3292e-02  3.6504e-01\n",
      "  1.4141e-01  4.8318e-01  1.6634e-01 -4.7567e-01  3.0030e-01  2.7269e-01\n",
      " -3.5838e-01 -3.4349e-01 -4.7118e-01 -4.6217e-01 -3.7760e-01  4.3310e-01\n",
      "  1.5368e-01 -1.8126e-01  3.3951e-01  3.7809e-01  2.8463e-01 -5.1584e-01\n",
      " -1.2181e-01  1.0491e-01  5.1566e-01  3.6216e-01  5.3154e-01  5.8073e-01\n",
      "  4.7118e-01 -3.0523e-01  2.0825e-01 -4.1196e-01 -1.0296e-01 -4.1626e-01\n",
      "  3.2150e-01 -1.4265e-01 -2.9571e-01 -4.0106e-01 -4.0727e-01 -2.3520e-02\n",
      " -1.2603e-01  4.8750e-01  3.2594e-01 -1.5487e-01  1.2768e-01  7.5144e-02\n",
      "  4.0369e-02  1.8373e-01 -5.9706e-01  2.7958e-01  2.3320e-01 -5.2678e-01\n",
      " -5.1151e-01 -9.2733e-01  3.6204e-01 -1.3234e-01  3.8635e-01 -2.2561e-01\n",
      "  3.8434e-01 -5.2130e-01  4.3128e-02 -4.1841e-01 -2.8536e-01 -8.1008e-01\n",
      " -4.8664e-01  2.9929e-01  6.1894e-01 -2.2276e-01  4.8597e-02 -8.9643e-02]\n",
      "is (300,) [-8.4961e-02  5.0200e-01  2.3823e-03 -1.6755e-01  3.0721e-01 -2.3762e-01\n",
      "  1.6069e-01 -3.6786e-01 -5.8347e-02  2.4990e+00 -2.3647e-03  1.0732e-02\n",
      " -3.0422e-01  8.4579e-02 -4.0299e-02 -4.1562e-01 -2.4494e-02  1.4691e+00\n",
      " -5.2932e-02 -7.4413e-02 -3.9244e-01 -3.2535e-01 -2.2333e-01  5.6823e-03\n",
      "  3.5675e-01  1.9445e-01  5.6762e-02 -4.5502e-02 -2.8105e-01 -5.8896e-02\n",
      " -9.8626e-02  9.2177e-02  3.3172e-01 -3.9967e-02 -1.1766e-01  4.8373e-02\n",
      " -6.2241e-02 -1.0413e-01  9.9263e-04 -4.8925e-01  3.4786e-01  3.2724e-01\n",
      "  1.3882e-01 -1.9917e-01  1.2995e-01  6.0549e-02 -2.3714e-01 -5.1295e-01\n",
      " -3.7396e-01  1.2902e-01  5.5797e-02  3.3444e-01 -1.8025e-01 -3.4740e-02\n",
      "  2.8323e-01 -9.5301e-02  2.1143e-01 -7.6149e-02  1.5069e-01 -1.7441e-01\n",
      " -7.4768e-03 -7.8287e-02 -1.2751e-01  2.2545e-01  3.5101e-02 -6.1015e-01\n",
      " -2.6812e-01  6.1632e-02 -3.0503e-01 -1.3405e-01 -4.4271e-01 -1.7720e-01\n",
      "  1.7663e-01 -3.1210e-01 -2.5722e-01 -2.4858e-02  7.2504e-02 -7.9759e-02\n",
      " -1.9214e-01  5.9602e-01  1.2880e-01 -7.4629e-02 -1.5812e-01  3.6394e-01\n",
      "  2.3055e-01 -4.2175e-01 -9.0651e-02 -3.0085e-01  1.7940e-01 -2.9786e-01\n",
      " -1.0642e-01  4.7239e-01 -1.3837e-01 -1.0161e-01  8.0134e-02  4.0715e-02\n",
      " -3.6976e-01 -3.7066e-02  1.0436e-01  1.7904e-01  1.5702e-01 -7.4670e-02\n",
      " -2.9431e-01  1.2829e-01  5.5211e-02 -4.3906e-01 -6.8231e-02  9.7107e-02\n",
      " -2.8209e-01 -8.6528e-02 -2.4204e-01  2.8734e-02 -2.1509e-01  2.7152e-02\n",
      " -1.7996e-01  1.9317e-01 -2.7929e-01  2.9415e-01 -1.0965e-01 -1.0432e-01\n",
      " -5.2170e-01 -4.6789e-02  1.3743e-01 -1.5518e-01 -1.0359e-01  1.8853e-01\n",
      " -1.2684e-01 -6.7278e-01  3.4483e-02 -2.2937e-01 -9.8073e-02 -7.0157e-02\n",
      "  8.4374e-02  2.6594e-01  2.3104e-01 -2.9251e-01 -8.7209e-02 -2.3342e-01\n",
      "  6.3759e-02 -1.3556e-01 -8.4046e-01  2.4681e-01  3.0498e-01  3.5438e-01\n",
      "  1.4137e-01 -3.6720e-01  2.3321e-01 -1.5497e-01  4.8364e-01  1.4711e-02\n",
      " -2.4176e-01  3.7589e-02  1.9829e-01 -6.9403e-02 -1.7362e-03  4.1694e-02\n",
      " -3.4193e-01 -2.0034e-01 -4.5581e-01 -1.2504e-01  1.3954e-01  3.2275e-02\n",
      " -5.2130e-03  4.5422e-02 -2.6574e-03 -2.6266e-01  6.4168e-02 -1.4231e-01\n",
      "  3.5709e-04 -2.3253e-01  2.7615e-02 -7.4282e-02  1.8671e-01 -1.2994e-01\n",
      " -4.3731e-01  1.4550e-01  4.4838e-02 -1.9022e-01 -1.5401e-01  1.4188e-01\n",
      "  9.8269e-02 -4.2930e-02 -2.7478e-01 -3.3224e-01 -3.2167e-01 -1.0509e-01\n",
      " -1.9816e-01 -6.5097e-02 -9.1251e-02  1.9528e-01 -3.3297e-01 -1.5504e-01\n",
      " -4.7688e-01  3.1985e-01  1.9886e-01  1.1501e-01  5.5757e-02 -5.4307e-02\n",
      "  2.8851e-01  2.7982e-01  1.3960e-02 -1.2891e-03 -2.3128e-01  7.5396e-02\n",
      "  4.3587e-02 -1.3937e-01 -6.2935e-02  1.2568e-01  9.5235e-02 -8.5203e-02\n",
      " -2.4241e-01 -4.8771e-02  9.5937e-02 -2.2347e-01  2.3503e-01  3.1517e-01\n",
      " -1.4900e-02  2.1739e-01 -1.9431e-01 -2.3255e-01 -2.2961e-01  4.8297e-02\n",
      "  1.6050e-01 -1.6100e-02  4.2770e-02 -3.2367e-01  1.4680e-01  2.4551e-01\n",
      "  7.5506e-02 -3.9703e-02 -1.0321e-01  1.6194e-01  2.7132e-01  4.6348e-02\n",
      " -9.2743e-02 -1.4929e-01  2.7378e-01 -3.6958e-01 -4.1530e-01  1.8402e-01\n",
      " -4.9775e-02  6.9670e-02  1.3447e-01  1.7788e-01 -4.7586e-02 -3.6491e-01\n",
      " -1.3733e-01 -4.8119e-01  2.4681e-01 -8.9842e-02  3.7939e-02 -1.8284e-01\n",
      "  4.7012e-01 -9.9584e-02 -1.8365e-01 -7.1821e-02  4.1607e-01 -1.8581e-01\n",
      "  1.8400e-01 -2.9028e-02  4.1228e-01  2.2856e-02  5.0915e-02 -1.1911e-01\n",
      "  8.1231e-02  1.3845e-01  4.6595e-02 -4.3974e-02  6.3601e-01  3.7101e-03\n",
      "  9.3937e-02 -9.3442e-02 -4.7606e-01 -2.6427e-01 -2.3044e-02 -5.8241e-02\n",
      "  1.1440e-01 -5.1702e-02  3.5225e-01  2.5341e-01  5.7256e-01  2.2867e-01\n",
      "  8.5401e-03 -6.2531e-02 -3.2118e-02 -1.5647e-01 -8.4344e-02  7.6667e-02\n",
      "  3.4515e-01 -1.9452e-01  8.7003e-02 -7.8201e-02 -6.9673e-02 -1.6993e-01\n",
      "  2.3598e-01  2.7550e-01 -6.7180e-02 -2.1511e-01 -2.6304e-01 -6.0173e-03]\n",
      "green (300,) [-7.2368e-02  2.3320e-01  1.3726e-01 -1.5663e-01  2.4844e-01  3.4987e-01\n",
      " -2.4170e-01 -9.1426e-02 -5.3015e-01  1.3413e+00 -8.6785e-01 -1.3183e-01\n",
      " -5.9679e-01 -3.4415e-01 -1.6121e-01 -9.2512e-04  5.3267e-01  2.1329e+00\n",
      "  2.1933e-02 -5.1933e-01  3.6557e-01 -1.2978e-02 -2.7154e-01  4.8964e-03\n",
      " -1.1849e-01 -3.8338e-01 -4.8944e-01  4.9147e-01  1.3664e-01 -9.6163e-02\n",
      " -2.8429e-02  3.9630e-03  1.5542e-01 -2.9680e-01 -1.4895e-01 -5.5311e-02\n",
      "  3.0003e-01  1.6376e-01 -1.6941e-01 -1.0166e-01  5.2141e-01  8.5416e-02\n",
      "  1.6017e-02 -7.9741e-02  1.5934e-01  8.6290e-02 -2.1192e-01 -8.0312e-03\n",
      "  2.0699e-01 -2.0541e-01 -1.3612e-01  2.4044e-02 -1.7975e-02 -2.7537e-01\n",
      "  5.5046e-01 -7.4320e-01 -1.0718e-01  8.3590e-01  4.5894e-02 -8.3839e-03\n",
      " -3.7027e-01 -3.8694e-01  1.4741e-01 -6.2706e-02  5.5882e-01 -3.5788e-02\n",
      " -3.7742e-01 -2.5088e-01 -3.2712e-01 -2.1363e-02 -1.1778e-01  1.0936e-02\n",
      " -4.0838e-02  1.9662e-01 -2.0128e-01 -4.7566e-02  1.1487e-01 -9.0004e-02\n",
      "  1.0354e-01 -5.2373e-01 -1.1288e-01  2.3075e-01  4.3984e-01  5.4876e-01\n",
      "  1.9629e-01 -2.9718e-01  7.1773e-01  1.3269e+00  6.2276e-02 -8.8419e-02\n",
      "  3.5253e-01  6.1762e-01  6.2818e-01  2.1847e-02  1.1744e-01  1.4717e-01\n",
      "  2.4852e-02  3.1065e-01 -3.0706e-02 -4.8994e-01  1.9092e-01 -5.1000e-02\n",
      " -1.9395e-01 -4.9768e-01 -3.4417e-01 -8.2097e-01 -4.9253e-01  3.0066e-01\n",
      " -1.1905e-01  3.5405e-01 -5.9503e-01 -5.9864e-01 -9.2760e-02 -1.4563e-01\n",
      "  6.8754e-01  1.8893e-01 -4.6852e-02  1.0246e-01 -8.7789e-02 -3.2801e-01\n",
      "  3.1215e-01 -1.7373e-01 -3.4827e-01 -1.9547e-01  1.1008e-01  2.2747e-01\n",
      "  4.4502e-01  8.1171e-02 -3.8463e-03 -1.9223e-01 -1.6651e-01  3.9317e-02\n",
      "  2.3909e-01 -3.0472e-01 -2.9583e-01 -6.2451e-01  1.0243e-01 -2.3324e-01\n",
      "  5.0008e-01  8.9740e-02 -2.1251e+00  2.4246e-01  2.7600e-01  1.1749e-01\n",
      "  7.1881e-02  1.7860e-01 -4.4795e-03  1.5575e-01 -2.7073e-01 -8.8036e-02\n",
      " -1.1564e-02 -1.4186e-02  4.9359e-01  1.6096e-01 -4.4652e-01 -2.0159e-01\n",
      " -3.1921e-01  4.0095e-03 -3.9027e-01  2.6482e-01 -8.7063e-02  3.9982e-01\n",
      " -3.0174e-01  3.6335e-01  6.5750e-02 -4.8644e-01 -1.8118e-01 -7.6974e-01\n",
      "  1.7686e-01  3.7618e-01  1.1485e-01  9.7655e-03 -3.1654e-01  7.6573e-02\n",
      " -2.9506e-01 -2.2645e-01  6.8611e-01  6.6346e-02  2.2698e-01 -2.0357e-01\n",
      " -1.1136e-01 -3.9789e-02 -3.1132e-01 -3.9395e-01 -2.6340e-01  4.1417e-02\n",
      " -2.2766e-01 -1.5583e-01 -3.9518e-01 -1.7292e-01  3.4403e-01  4.0990e-01\n",
      " -9.3649e-02 -1.2536e-01  2.1836e-01  2.7454e-01  2.3929e-01  5.4202e-01\n",
      " -1.8898e-01  6.1104e-02 -9.9625e-02  6.9587e-02 -1.7275e-01  3.9217e-01\n",
      "  9.1343e-02  2.5958e-01  5.0131e-01  1.0328e-01  2.8023e-01 -4.2147e-01\n",
      " -2.3985e-01  5.0814e-01  4.0660e-01 -3.2745e-03  1.3557e-02  2.6442e-01\n",
      "  1.8914e-02 -1.9332e-02  2.0762e-01 -3.9842e-01 -5.6105e-01 -2.6695e-01\n",
      " -7.6739e-03  2.8867e-01  3.1247e-01 -4.4065e-03  3.4002e-01 -5.1330e-02\n",
      " -4.3934e-01  6.1596e-02  1.4591e-01  3.7920e-01  4.3088e-01  3.6122e-01\n",
      " -2.0847e-01  5.6458e-01 -5.6009e-02 -4.6236e-01  8.1828e-01  8.1877e-01\n",
      " -1.5978e-01 -3.0881e-01 -5.5235e-01  4.7371e-02 -3.8537e-02  3.7726e-01\n",
      "  6.0784e-02 -4.3161e-01 -3.3027e-01 -1.8559e-01  1.1674e-01 -1.3420e-01\n",
      " -2.0262e-01  8.2621e-02  3.2163e-01  2.5451e-01  1.3104e-01  5.2760e-01\n",
      " -4.7345e-03  1.9238e-01 -6.3701e-02  2.6855e-01  1.2537e-01  6.0333e-01\n",
      "  3.4068e-01 -3.6425e-01 -3.5315e-01 -4.3298e-01 -4.2086e-01  1.5704e-01\n",
      " -2.5552e-01  1.6895e-01  7.9552e-02 -3.1513e-01  8.5769e-02 -7.9049e-02\n",
      "  4.9882e-04  4.1551e-01  1.3062e-01  2.1869e-01  1.7056e-01 -2.3690e-01\n",
      " -3.9074e-01  5.9123e-02 -8.0229e-02  1.1957e-01  3.7294e-01  3.8980e-01\n",
      "  4.2767e-01 -1.1234e-01 -4.0517e-01  2.4357e-01  4.3730e-01 -4.6152e-01\n",
      " -3.5271e-01  3.3625e-01  6.9899e-02 -1.1155e-01  5.3293e-01  7.1268e-01]\n",
      ". (300,) [ 0.012001   0.20751   -0.12578   -0.59325    0.12525    0.15975\n",
      "  0.13748   -0.33157   -0.13694    1.7893    -0.47094    0.70434\n",
      "  0.26673   -0.089961  -0.18168    0.067226   0.053347   1.5595\n",
      " -0.2541     0.038413  -0.01409    0.056774   0.023434   0.024042\n",
      "  0.31703    0.19025   -0.37505    0.035603   0.1181     0.012032\n",
      " -0.037566  -0.5046    -0.049261   0.092351   0.11031   -0.073062\n",
      "  0.33994    0.28239    0.13413    0.070128  -0.022099  -0.28103\n",
      "  0.49607   -0.48693   -0.090964  -0.1538    -0.38011   -0.014228\n",
      " -0.19392   -0.11068   -0.014088  -0.17906    0.24509   -0.16878\n",
      " -0.15351   -0.13808    0.02151    0.13699    0.0068061 -0.14915\n",
      " -0.38169    0.12727    0.44007    0.32678   -0.46117    0.068687\n",
      "  0.34747    0.18827   -0.31837    0.4447    -0.2095    -0.26987\n",
      "  0.48945    0.15388    0.05295   -0.049831   0.11207    0.14881\n",
      " -0.37003    0.30777   -0.33865    0.045149  -0.18987    0.26634\n",
      " -0.26401   -0.47556    0.68381   -0.30653    0.24606    0.31611\n",
      " -0.071098   0.030417   0.088119   0.045025   0.20125   -0.21618\n",
      " -0.36371   -0.25948   -0.42398   -0.14305   -0.10208    0.21498\n",
      " -0.21924   -0.17935    0.21546    0.13801    0.24504   -0.2559\n",
      "  0.054815   0.21307    0.2564    -0.25673    0.17961   -0.47638\n",
      " -0.25181   -0.0091498 -0.054362  -0.21007    0.12597   -0.40795\n",
      " -0.021164   0.20585    0.18925   -0.0051896 -0.51394    0.28862\n",
      " -0.077748  -0.27676    0.46567   -0.14225   -0.17879   -0.4357\n",
      " -0.32481    0.15034   -0.058367   0.49652    0.20472    0.019866\n",
      "  0.13326    0.12823   -1.0177     0.29007    0.28995    0.029994\n",
      " -0.10763    0.28665   -0.24387    0.22905   -0.26249   -0.069269\n",
      " -0.17889    0.21936    0.15146    0.04567   -0.050497   0.071482\n",
      " -0.1027    -0.080705   0.30296    0.031302   0.26613   -0.0060951\n",
      "  0.10313   -0.39987   -0.043945  -0.057625   0.08702   -0.098152\n",
      "  0.22835   -0.005211   0.038075   0.01591   -0.20622    0.021853\n",
      "  0.0040426 -0.043063  -0.002294  -0.26097   -0.25802   -0.28158\n",
      " -0.23118   -0.010404  -0.30102   -0.4042     0.014653  -0.10445\n",
      "  0.30377   -0.20957    0.3119     0.068272   0.1008     0.010423\n",
      "  0.54011    0.29865    0.12653    0.013761   0.21738   -0.39521\n",
      "  0.066633   0.50327    0.14913   -0.11554    0.010042   0.095698\n",
      "  0.16607   -0.18808    0.055019   0.026715  -0.3164    -0.046583\n",
      " -0.051591   0.023475  -0.11007    0.085642   0.28394    0.040497\n",
      "  0.071986   0.14157   -0.021199   0.44718    0.20088   -0.12964\n",
      " -0.067183   0.47614    0.13394   -0.17287   -0.37324   -0.17285\n",
      "  0.02683   -0.1316     0.09116   -0.46487    0.1274    -0.090159\n",
      " -0.10552    0.068006  -0.13381    0.17056    0.089509  -0.23133\n",
      " -0.27572    0.061534  -0.051646   0.28377    0.25286   -0.24139\n",
      " -0.19905    0.12049   -0.1011     0.27392    0.27843    0.26449\n",
      " -0.18292   -0.048961   0.19198    0.17192    0.33659   -0.20184\n",
      " -0.34305   -0.24553   -0.15399    0.3945     0.22839   -0.25753\n",
      " -0.25675   -0.37332   -0.23884   -0.048816   0.78323    0.18851\n",
      " -0.26477    0.096566   0.062658  -0.30668   -0.43334    0.10006\n",
      "  0.21136    0.039459  -0.11077    0.24421    0.60942   -0.46646\n",
      "  0.086385  -0.39702   -0.23363    0.021307  -0.10778   -0.2281\n",
      "  0.50803    0.11567    0.16165   -0.066737  -0.29556    0.022612\n",
      " -0.28135    0.0635     0.14019    0.13871   -0.36049   -0.035    ]\n"
     ]
    }
   ],
   "source": [
    "# create sentence.\n",
    "sentence = nlp('The grass is green .')\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token.text, token.vector.shape, token.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "- Given a document, determine the topic of the document\n",
    "- For this task, we'll use the Brown corpus of texts accessible via NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/hunterbarclay/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/v1d1731j3qbgx44s5gmrbf_c0000gn/T/ipykernel_79160/3865087430.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for fileid in tqdm(brown.fileids(categories=[cat])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92beaa49170a4b768b8199f5c96000bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belles_lettres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004299af1d6341639f3137b029b95e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "editorial\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d19413cae41403197f2c023eef902e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383c9b87e4fe4e2da9b0675ace64760c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269dc61dc0c649c5a6a6fca4274af920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hobbies\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33518377cbf347e2a1e23772baa6489b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fa8342d4f14400834a489808637916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504f137e4b7c499a95d38a944914f917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lore\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76af435596f84c2cba969dc75af181ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mystery\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45829b398cb44e4d94a1a60b0170762d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8c8f15f63d4beba5d2220dd36a1cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f7f93eacd3497bb01ac9b1bd4e6ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca35ee36950b40ada224497531b5e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cece8a0166954796b433998eb829e383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science_fiction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15276eb3c0ad4008983fe809a5c2174c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm # tqdm displays a progress bar\n",
    "from tqdm import tqdm_notebook as tqdm # tqdm is a nice process indicator \n",
    "\n",
    "category_vectors = []\n",
    "\n",
    "cats = brown.categories()\n",
    "    \n",
    "# for each category\n",
    "for cat in cats:\n",
    "    print(cat)\n",
    "    # grab all of the documents\n",
    "    for fileid in tqdm(brown.fileids(categories=[cat])):\n",
    "        sents = brown.sents(fileids=[fileid])\n",
    "        sent_vecs = []\n",
    "        for sent in sents:\n",
    "            sent = ' '.join(sent)\n",
    "            sent = nlp(sent)\n",
    "            # grab all of the words, find their embedding, sum all embeddings\n",
    "            word_sum = np.sum([tok.vector for tok in sent], axis=0) # why axis=0?\n",
    "            # add the now summed embedding to the list for this category\n",
    "            sent_vecs.append(word_sum)\n",
    "        category_vectors.append((cat,np.sum(sent_vecs, axis=0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keys,values=zip(*category_vectors) # unzip using a *\n",
    "\n",
    "data = pd.DataFrame({'cat':keys,'vectors':values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventure</td>\n",
       "      <td>[-22.51716, 449.9568, -423.67093, -223.53218, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventure</td>\n",
       "      <td>[33.477146, 375.79608, -379.33813, -253.57874,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventure</td>\n",
       "      <td>[82.20694, 250.26768, -268.21576, -123.84788, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat                                            vectors\n",
       "0  adventure  [-22.51716, 449.9568, -423.67093, -223.53218, ...\n",
       "1  adventure  [33.477146, 375.79608, -379.33813, -253.57874,...\n",
       "2  adventure  [82.20694, 250.26768, -268.21576, -123.84788, ..."
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random baseline 0.06666666666666667\n",
      "most common baseline?\n",
      "adventure 0.058\n",
      "belles_lettres 0.15\n",
      "editorial 0.054\n",
      "fiction 0.058\n",
      "government 0.06\n",
      "hobbies 0.072\n",
      "humor 0.018\n",
      "learned 0.16\n",
      "lore 0.096\n",
      "mystery 0.048\n",
      "news 0.088\n",
      "religion 0.034\n",
      "reviews 0.034\n",
      "romance 0.058\n",
      "science_fiction 0.012\n"
     ]
    }
   ],
   "source": [
    "print('random baseline {}'.format(1.0/len(cat)))\n",
    "\n",
    "print('most common baseline?')\n",
    "for cat in cats:\n",
    "    print(cat, len(data[data.cat==cat])/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 2), (450, 2))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.1,random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.cat) \n",
    "X = [x for x in train.vectors]\n",
    "y = le.transform(train.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfr = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hunterbarclay/.pyenv/versions/3.12.9/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/hunterbarclay/.pyenv/versions/3.12.9/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = le.transform(test.cat)\n",
    "test_X = [x for x in test.vectors]\n",
    "\n",
    "score = accuracy_score(clfr.predict(test_X), test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "- GoogleNews-vectors-negative300.magnitude 0.4 (w2v)\n",
    "- wiki-news-300d-1M.magnitude 0.56 (bert)\n",
    "- glove.6B.300d.magnitude 0.52 (glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 2), (450, 2))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Horrific Neural Network\n",
    "\n",
    "I got it to like 65% at one point, but that's the best I've seen. With the large embedding set, the logistic regression got significantly better, so I just tinkered around for an hour or so until I finally got it to perform better than any of the numbers above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 300) (450, 15)\n",
      "(50, 300) (50, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#test = data.sample(frac=0.1,random_state=200)\n",
    "#train = data.drop(test.index)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "le.fit(data.cat)\n",
    "data_y = le.transform(data.cat).reshape(-1, 1) # this is magic\n",
    "ohe.fit(data_y)\n",
    "y = ohe.transform(le.transform(train.cat).reshape(-1, 1)).todense()\n",
    "\n",
    "X = np.array([x for x in train.vectors])\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "test_y = ohe.transform(le.transform(test.cat).reshape(-1, 1)).todense()\n",
    "test_X = np.array([x for x in test.vectors])\n",
    "\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3efb20050>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "model.add(Input((300,)))\n",
    "# Hidden Layers\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "# Output Layer\n",
    "model.add(Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=1000, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Data Accuracy\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9971 - loss: 0.0024\n",
      "\tTesting Data Accuracy\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5742 - loss: 0.2918\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tTraining Data Accuracy\")\n",
    "model.evaluate(X, y)\n",
    "print(\"\\tTesting Data Accuracy\")\n",
    "_, _ = model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Answers\n",
    "#### 1. What would you say is the neural network \"learning\"?\n",
    "\n",
    "The network is \"learning\" to produce the training outputs given the training inputs.\n",
    "\n",
    "#### 2. How does the depth or width of the network affect the training and the results?\n",
    "\n",
    "Higher width tends to result in overfitting. It allows the model to fit to specific situations in the training set rather than gaining and understanding of the data.\n",
    "Higher depth encourages more unique solutions to fitting to the training set that helps accuracy in the testing set, but results in higher training need.\n",
    "\n",
    "#### 3. As you made changes to the network, what do you notice about how hyperparameters (network depth, number of nodes, learning rate, etc.) and how they interact with each other? We said that neural networks are learning non-convex problems, but what about finding the best parameters? Is that a convex problem?\n",
    "\n",
    "Each hyperparameter brings something to the table. Some conflict in aspects and combine in others to reach a better result. It's definitely not a convex problem since you can go for multiple approaches in selecting your hyperparameters, and each set could produce similar results.\n",
    "\n",
    "#### 4. What is regularization? Why is it important?\n",
    "\n",
    "Regularization prevents from overfitting. It hinderences the network from learning in a way that essentially copies what it's see so it can better anticipate data it's never seen before.\n",
    "\n",
    "#### 5. Which activation functions did you choose (besides logitistic/sigmoid)? For one of the activation functions you tried, spend some time learning about it. Whereas logistic/sigmoid maps from inputs to a probability between 0-1, what does the activation function you chose do?\n",
    "\n",
    "I used the ReLU activation function. It zeros out all node values that are negative, while keeping the rest the same. This break from a simple linear activation function causes non-linearity in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
